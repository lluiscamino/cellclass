{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Práctica 1: Clasificación de células\n",
    "\n",
    "## Enunciado del problema\n",
    "La anemia de células falciformes es una alteración de la sangre que hace que los glóbulos rojos\n",
    "se deformen hasta adquirir una forma elongada, en vez de circular.\n",
    "\n",
    "Esta práctica consiste en clasificar un conjunto de células en tres clases diferentes\n",
    "(circulares - c, elongadas - e u otras - o) usando el **mínimo de características posibles**.\n",
    "\n",
    "<img alt=\"Glóbulos rojos en la sangre\" src=\"example.jpeg\" width=\"600\"/>\n",
    "\n",
    "## Descripción del dataset\n",
    "El dataset está formado por cuatro archivos CSV que contienen diferentes atributos sobre cada célula.\n",
    "Cada célula está identificada por un ID único, para poder ser reconocida en los diferentes archivos.\n",
    "\n",
    "Los cuatro archivos de datos son los siguientes:\n",
    "- `info.csv`: Contiene el path a la imagen de la célula en cuestión y su clase.\n",
    "- `color.csv`: Contiene todas las características referentes al color extraídas de cada célula.\n",
    "- `shape.csv`: Contiene todas las características referentes a la forma extraídas de cada célula.\n",
    "- `texture.csv`: Contiene todas las características referentes a la textura extraídas de cada célula.\n",
    "\n",
    "Estas características han sido extraídas mediante técnicas de visión por computador.\n",
    "El dataset está formado completamente por datos numéricos y no contiene datos inválidos o vacíos.\n",
    "\n",
    "## Importación del dataset\n",
    "Para poder tratar este dataset de manera eficiente, se ha generado un nuevo fichero CSV que\n",
    "une los datos de los tres cuatro archivos de datos.\n",
    "\n",
    "Para agregar los datos en un solo fichero, se ha desarrollado un script, que es capaz de unir en un\n",
    "archivo los datos de entrenamiento así como los datos de test.\n",
    "\n",
    "## Análisis exploratorio de datos\n",
    "Una vez generado el fichero que une todos los datos de entrenamiento, se ha podido comprobar como este\n",
    "contiene 121 columnas (variables) y 445 filas (muestras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lluis/Desktop/cellclass/utils/utils.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data = data.drop(\"idx\", 1)\n",
      "/Users/lluis/Desktop/cellclass/utils/utils.py:15: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data = data.drop(\"path\", 1)\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_data\n",
    "\n",
    "X, y = get_data()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A continuación podemos ver una muestra de las características del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos de aprendizaje automático\n",
    "Una vez explicado el enunciado del problema y visto cómo se han importado los datos, podemos pasar a\n",
    "explicar los diferentes pasos que se han seguido para obtener el modelo final.\n",
    "\n",
    "### División del conjunto de datos en train y test\n",
    "En primer lugar, se ha hecho una división de los datos de entrenamiento en dos subconjuntos, para poder\n",
    "entrenar y posteriormente, evaluar el rendimiento del modelo.\n",
    "\n",
    "Esta división se ha hecho con el método `train_test_split` de `scikit``, dándole al subconjunto de test\n",
    "un tamaño del 30% del conjunto global."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=57)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Escalado de datos\n",
    "Adicionalmente, se han normalizado los datos mediante el escalado estándar usando la clase\n",
    "`StandardScaler``"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.utils import scale_data\n",
    "\n",
    "X_train, X_test = scale_data(X_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}