{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Enunciado del problema\n",
    "La anemia de células falciformes es una alteración de la sangre que hace que los glóbulos rojos\n",
    "se deformen hasta adquirir una forma elongada, en vez de circular.\n",
    "\n",
    "Esta práctica consiste en clasificar un conjunto de células en tres clases diferentes\n",
    "(circulares - c, elongadas - e u otras - o) usando el **mínimo de características posibles**.\n",
    "\n",
    "<img alt=\"Glóbulos rojos en la sangre\" src=\"example.jpeg\" width=\"600\"/>\n",
    "\n",
    "# Descripción del dataset\n",
    "El dataset está formado por cuatro archivos CSV que contienen diferentes atributos sobre cada célula.\n",
    "Cada célula está identificada por un ID único, para poder ser reconocida en los diferentes archivos.\n",
    "\n",
    "Los cuatro archivos de datos son los siguientes:\n",
    "- `info.csv`: Contiene el path a la imagen de la célula en cuestión y su clase.\n",
    "- `color.csv`: Contiene todas las características referentes al color extraídas de cada célula.\n",
    "- `shape.csv`: Contiene todas las características referentes a la forma extraídas de cada célula.\n",
    "- `texture.csv`: Contiene todas las características referentes a la textura extraídas de cada célula.\n",
    "\n",
    "Estas características han sido extraídas mediante técnicas de visión por computador.\n",
    "El dataset está formado completamente por datos numéricos y no contiene datos inválidos o vacíos.\n",
    "\n",
    "# Importación del dataset\n",
    "Para poder tratar este dataset de manera eficiente, se ha generado un nuevo fichero CSV que\n",
    "une los datos de los cuatro archivos de datos.\n",
    "\n",
    "Para agregar los datos en un solo fichero, se ha desarrollado un script, que es capaz de unir en un\n",
    "archivo los datos de entrenamiento así como los datos de test.\n",
    "\n",
    "# Análisis exploratorio de datos\n",
    "Una vez generado el fichero que une todos los datos de entrenamiento, se ha podido comprobar como este\n",
    "contiene 121 columnas (variables) y 445 filas (muestras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(445, 121)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.utils import get_data\n",
    "\n",
    "X, y = get_data()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A continuación podemos ver una muestra de las características del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Blue mean  Green mean  Red mean  Blue std  Green std  Red std  Hue mean  \\\n0   150.2912    118.8615  130.3895    5.2289     8.8786   8.4380  131.4628   \n1   158.2896    126.3923  144.6604    6.0253    10.1304   9.7674  136.0408   \n2   154.9417    127.0161  143.5692    5.2608    10.3249   9.3363  138.2455   \n3   151.9344    115.6617  132.1807    8.5218    13.4602  14.1391  132.4725   \n4   152.5914    123.9839  138.9914    4.7207     8.9208   8.7410  136.2724   \n\n   Saturation mean  Value mean  Hue std  ...  Correlation3  Correlation4  \\\n0          53.4965    150.4433  10.9909  ...        0.8115        0.8603   \n1          53.0517    159.4682  18.7224  ...        0.7850        0.8285   \n2          46.8765    155.5516  15.9481  ...        0.7870        0.8440   \n3          63.1637    153.4545  21.6648  ...        0.7484        0.8133   \n4          48.6253    153.1451  14.3680  ...        0.8152        0.8573   \n\n   Correlation5  Correlation6  Correlation7  Correlation8  Correlation9  \\\n0        0.8183        0.8570        0.8081        0.8603        0.7689   \n1        0.7694        0.8347        0.7821        0.8285        0.7014   \n2        0.8015        0.8651        0.7957        0.8440        0.7378   \n3        0.7608        0.8399        0.7608        0.8133        0.6838   \n4        0.8087        0.8626        0.8146        0.8573        0.7469   \n\n   Correlation10  Correlation11  Correlation12  \n0         0.7501         0.7577         0.7627  \n1         0.7150         0.7294         0.7250  \n2         0.7645         0.7440         0.7277  \n3         0.7264         0.6996         0.6775  \n4         0.7651         0.7627         0.7534  \n\n[5 rows x 121 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Blue mean</th>\n      <th>Green mean</th>\n      <th>Red mean</th>\n      <th>Blue std</th>\n      <th>Green std</th>\n      <th>Red std</th>\n      <th>Hue mean</th>\n      <th>Saturation mean</th>\n      <th>Value mean</th>\n      <th>Hue std</th>\n      <th>...</th>\n      <th>Correlation3</th>\n      <th>Correlation4</th>\n      <th>Correlation5</th>\n      <th>Correlation6</th>\n      <th>Correlation7</th>\n      <th>Correlation8</th>\n      <th>Correlation9</th>\n      <th>Correlation10</th>\n      <th>Correlation11</th>\n      <th>Correlation12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>150.2912</td>\n      <td>118.8615</td>\n      <td>130.3895</td>\n      <td>5.2289</td>\n      <td>8.8786</td>\n      <td>8.4380</td>\n      <td>131.4628</td>\n      <td>53.4965</td>\n      <td>150.4433</td>\n      <td>10.9909</td>\n      <td>...</td>\n      <td>0.8115</td>\n      <td>0.8603</td>\n      <td>0.8183</td>\n      <td>0.8570</td>\n      <td>0.8081</td>\n      <td>0.8603</td>\n      <td>0.7689</td>\n      <td>0.7501</td>\n      <td>0.7577</td>\n      <td>0.7627</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>158.2896</td>\n      <td>126.3923</td>\n      <td>144.6604</td>\n      <td>6.0253</td>\n      <td>10.1304</td>\n      <td>9.7674</td>\n      <td>136.0408</td>\n      <td>53.0517</td>\n      <td>159.4682</td>\n      <td>18.7224</td>\n      <td>...</td>\n      <td>0.7850</td>\n      <td>0.8285</td>\n      <td>0.7694</td>\n      <td>0.8347</td>\n      <td>0.7821</td>\n      <td>0.8285</td>\n      <td>0.7014</td>\n      <td>0.7150</td>\n      <td>0.7294</td>\n      <td>0.7250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>154.9417</td>\n      <td>127.0161</td>\n      <td>143.5692</td>\n      <td>5.2608</td>\n      <td>10.3249</td>\n      <td>9.3363</td>\n      <td>138.2455</td>\n      <td>46.8765</td>\n      <td>155.5516</td>\n      <td>15.9481</td>\n      <td>...</td>\n      <td>0.7870</td>\n      <td>0.8440</td>\n      <td>0.8015</td>\n      <td>0.8651</td>\n      <td>0.7957</td>\n      <td>0.8440</td>\n      <td>0.7378</td>\n      <td>0.7645</td>\n      <td>0.7440</td>\n      <td>0.7277</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.9344</td>\n      <td>115.6617</td>\n      <td>132.1807</td>\n      <td>8.5218</td>\n      <td>13.4602</td>\n      <td>14.1391</td>\n      <td>132.4725</td>\n      <td>63.1637</td>\n      <td>153.4545</td>\n      <td>21.6648</td>\n      <td>...</td>\n      <td>0.7484</td>\n      <td>0.8133</td>\n      <td>0.7608</td>\n      <td>0.8399</td>\n      <td>0.7608</td>\n      <td>0.8133</td>\n      <td>0.6838</td>\n      <td>0.7264</td>\n      <td>0.6996</td>\n      <td>0.6775</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.5914</td>\n      <td>123.9839</td>\n      <td>138.9914</td>\n      <td>4.7207</td>\n      <td>8.9208</td>\n      <td>8.7410</td>\n      <td>136.2724</td>\n      <td>48.6253</td>\n      <td>153.1451</td>\n      <td>14.3680</td>\n      <td>...</td>\n      <td>0.8152</td>\n      <td>0.8573</td>\n      <td>0.8087</td>\n      <td>0.8626</td>\n      <td>0.8146</td>\n      <td>0.8573</td>\n      <td>0.7469</td>\n      <td>0.7651</td>\n      <td>0.7627</td>\n      <td>0.7534</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 121 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modelos de aprendizaje automático\n",
    "Una vez explicado el enunciado del problema y visto cómo se han importado los datos, podemos pasar a\n",
    "explicar los diferentes pasos que se han seguido para obtener el modelo final.\n",
    "\n",
    "## División del conjunto de datos en train y test\n",
    "En primer lugar, se ha hecho una división de los datos de entrenamiento en dos subconjuntos, para poder\n",
    "entrenar y posteriormente, evaluar el rendimiento del modelo.\n",
    "\n",
    "Esta división se ha hecho con el método `train_test_split` de `scikit`, dándole al subconjunto de test\n",
    "un tamaño del 30% del conjunto global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Escalado de datos\n",
    "Adicionalmente, se han normalizado los datos mediante el escalado estándar usando la clase\n",
    "`StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import scale_data\n",
    "\n",
    "X_train, X_test = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Perceptrón, regresión logística, Random Forest y SVM básicos\n",
    "La primera estrategia para intentar construir un modelo de aprendizaje automático capaz de clasificar\n",
    "correctamente las células, ha sido entrenar cuatro clasificadores distintos utilizando todas las\n",
    "características del dataset.\n",
    "\n",
    "Los clasificadores elegidos para esta primera fase son el perceptrón, regresión logística, Random forest y\n",
    "Support Vector Machine (SVM) linear.\n",
    "\n",
    "### Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  0  1]\n",
      " [ 0 43  2]\n",
      " [ 1  2 36]]\n",
      "Precision: 0.9552238805970149\n",
      "Recall:    0.9552238805970149\n",
      "F1 score:  0.9552238805970149\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import print_model_performance_metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"perceptron\", eta0=1, max_iter=1000, random_state=5)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  0  2]\n",
      " [ 0 41  4]\n",
      " [ 1  0 38]]\n",
      "Precision: 0.9526970896906932\n",
      "Recall:    0.9477611940298507\n",
      "F1 score:  0.9485273776308099\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log\", eta0=1, max_iter=1000, random_state=5)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 41  4]\n",
      " [ 0  1 38]]\n",
      "Precision: 0.9642857142857143\n",
      "Recall:    0.9626865671641791\n",
      "F1 score:  0.9627342216122453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  0  3]\n",
      " [ 0 42  3]\n",
      " [ 1  1 37]]\n",
      "Precision: 0.9438056808978363\n",
      "Recall:    0.9402985074626866\n",
      "F1 score:  0.94111082894951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1.0, kernel=\"linear\", probability=True, random_state=5)\n",
    "svc.fit(X_train, y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación\n",
    "\n",
    "| Clasificador       | F1 Score (test split)  | F1 Score (test data)  |\n",
    "| ------------------ |:----------------------:|:---------------------:|\n",
    "| Perceptrón         | 0.9552                 | 0.4897                |\n",
    "| Regresión logística| 0.9485                 | 0.4955                |\n",
    "| Random forest      | 0.9627                 | 0.2838                |\n",
    "| SVM                | 0.9402                 | 0.1367                |\n",
    "\n",
    "Podemos observar que, pese a que el rendimiento de todos los modelos parece ser bueno juzgando por el subconjunto de\n",
    "entrenamiento, una vez subido a la plataforma Kaggle para ser evaluado con el conjunto `test`, el rendimiento de ningún\n",
    "modelo es aceptable.\n",
    "\n",
    "## Eliminación de características colineales\n",
    "Uno de los motivos que puede llevar a un rendimiento bajo de los modelos lineales, es la existencia de características\n",
    "colineales en el dataset.\n",
    "\n",
    "Con el objetivo de estudiar la correlación entre las características del dataset, se ha dibujado un _heatmap_ en forma\n",
    "de matriz, que indica la correlación entre las diferentes variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "corr = X.corr().abs()\n",
    "plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds, fmt=\".1f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar como existe colinealidad entre varias características diferentes. Esta podría ser una explicación\n",
    "de los bajos resultados de los modelos del punto anterior.\n",
    "\n",
    "Para solucionar este problema, se ha optado por eliminar todas aquellas características colineales que superen un\n",
    "cierto umbral de correlación. Para este fin, se ha usado una adaptación de la función\n",
    "[remove_collinear_features](https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on/61938339#61938339)\n",
    "([Synergix](https://stackoverflow.com/users/5240904/synergix)).\n",
    "\n",
    "El umbral a partir del cual se eliminarán las características colineales es 0.6. Una vez eliminadas las características\n",
    "colineales que superen este umbral, podemos volver a calcular la matriz de correlación, que ahora mostrará una baja\n",
    "correlación entre características diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from feature_selection.filter_method import remove_collinear_features\n",
    "\n",
    "remove_collinear_features(X, 0.6)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(X.corr().abs(), annot=True, cmap=plt.cm.Reds, fmt=\".1f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Una vez realizado este proceso, podemos volver a entrenar los modelos del apartado anterior y comparar los nuevos\n",
    "resultados de rendimiento.\n",
    "\n",
    "### Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import print_model_performance_metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=57)\n",
    "X_train, X_test = scale_data(X_train, X_test)\n",
    "clf = SGDClassifier(loss=\"perceptron\", eta0=1, max_iter=1000, random_state=5)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"log\", eta0=1, max_iter=1000, random_state=5)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1.0, kernel=\"linear\", probability=True, random_state=5)\n",
    "svc.fit(X_train, y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "\n",
    "print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación\n",
    "\n",
    "| Clasificador       | F1 Score (test split)  | F1 Score (test data)  |\n",
    "| ------------------ |:----------------------:|:---------------------:|\n",
    "| Perceptrón         | 0.8283                 | 0.6854                |\n",
    "| Regresión logística| 0.8582                 | 0.6793                |\n",
    "| Random forest      | 0.9029                 | 0.2674                |\n",
    "| SVM                | 0.8582                 | 0.1367                |\n",
    "\n",
    "Podemos observar como los modelos más afectados por la multicolinealidad son el perceptrón y la regresión logística,\n",
    "cuyo _F1 score_ sobre el dataset de test ha mejorado hasta un 0.6854 y un 0.6793, respectivamente.\n",
    "\n",
    "También cabe destacar la diferencia de la medida de rendimiento en el split de datos y en Kaggle. En concreto, esta\n",
    "diferencia se aprecia significativamente en los modelos Random forest y SVM. Esta diferencia indica un claro caso de\n",
    "_overfitting_ en los modelos mencionados. Es decir, los modelos están \"memorizando\" los datos de entrenamiento pero no\n",
    "son capaces de generalizar sus predicciones.\n",
    "\n",
    "## Ajuste de hiperparámetros en SVM\n",
    "\n",
    "### Elección de kernel\n",
    "\n",
    "Hasta el momento, el modelo Support Vector Machine ha tenido el peor rendimiento de los cuatro tipos de modelos que se\n",
    "han entrenado.\n",
    "\n",
    "Una de las maneras de resolver este problema, puede ser entrenar un modelo de tipo SVM con un kernel no lineal.\n",
    "Los kernels disponibles son el linear (`linear`), polinómico (`poly`), función de base radial (`rbf`) y sigmoide (`sigmoid`).\n",
    "\n",
    "Entrenaremos un modelo para cada kernel distinto y compararemos los resultados de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"\\nSVC kernel=\", kernel)\n",
    "    svc = SVC(C=1.0, kernel=kernel, probability=True, random_state=5)\n",
    "    svc.fit(X_train, y_train)\n",
    "    prediction = svc.predict(X_test)\n",
    "    print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparación\n",
    "\n",
    "Una vez calculado el _F1 score_ sobre el split de datos de test, pasamos a subir los datos de Kaggle y a construir una\n",
    "tabla de resultados.\n",
    "\n",
    "| Clasificador       | F1 Score (test split)  | F1 Score (test data)  |\n",
    "| ------------------ |:----------------------:|:---------------------:|\n",
    "| SVM kernel lineal  | 0.8594                 | 0.1367                |\n",
    "| SVM kernel poly    | 0.7879                 | 0.6656                |\n",
    "| SVM kernel rbf     | 0.8474                 | 0.3000                |\n",
    "| SVM kernel sigmoid | 0.8442                 | 0.5808                |\n",
    "\n",
    "Se puede observar como los modelos con un kernel polinómico y sigmoide tienen un rendimiento bastante mejor que el\n",
    "anterior modelo con un kernel lineal.\n",
    "\n",
    "### Parámetro de regularización C\n",
    "\n",
    "Ahora que hemos comprobado que el kernel polinómico y sigmoide son los que tienen un mayor rendimiento para este\n",
    "conjunto de datos, podemos ajustar el hiperparámetro C. Entrenaremos varios modelo para los kernels polinómico y\n",
    "sigmoide con los siguientes valores para C: 1, 10, 100, 1000, y 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kernels = [\"poly\", \"sigmoid\"]\n",
    "c_values = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"\\nSVC kernel=\", kernel)\n",
    "    for c in c_values:\n",
    "        print(\"C=\", c)\n",
    "        svc = SVC(C=c, kernel=kernel, probability=True)\n",
    "        svc.fit(X_train, y_train)\n",
    "        prediction = svc.predict(X_test)\n",
    "        print_model_performance_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparación\n",
    "\n",
    "Una vez calculado el rendimiento del modelo con el split sobre los datos de entrenamiento, podemos pasar a subir las\n",
    "predicciones a Kaggle y comparar el rendimiento de los modelos en función del parámetro C.\n",
    "\n",
    "\n",
    "| Clasificador       | C      | F1 Score (test split)  | F1 Score (test data)  |\n",
    "| ------------------ |:------:|:----------------------:|:---------------------:|\n",
    "| SVM kernel poly    | 1      | 0.7879                 | 0.6656                |\n",
    "| SVM kernel poly    | 10     | 0.7876                 | 0.6216                |\n",
    "| SVM kernel poly    | 100    | 0.7640                 | 0.6231                |\n",
    "| SVM kernel poly    | 1000   | 0.7640                 | 0.6231                |\n",
    "| SVM kernel poly    | 10000  | 0.7640                 | 0.6231                |\n",
    "| SVM kernel sigmoid | 1      | 0.8442                 | 0.6003                |\n",
    "| SVM kernel sigmoid | 10     | 0.7579                 | 0.5137                |\n",
    "| SVM kernel sigmoid | 100    | 0.8022                 | 0.5152                |\n",
    "| SVM kernel sigmoid | 1000   | 0.7559                 | 0.5182                |\n",
    "| SVM kernel sigmoid | 10000  | 0.8017                 | 0.5182                |\n",
    "\n",
    "Podemos observar como los modelos con el parámetro de regularización por defecto (C=1) obtienen el mayor rendimiento.\n",
    "\n",
    "## Modelo resultante\n",
    "\n",
    "De todos los modelos de aprendizaje automático probados, el que mejor rendimiento ha dado de todos los entrenados\n",
    "ha sido el perceptrón. Por este motivo, será el modelo que utilizemos en la solución final.\n",
    "\n",
    "Para poder obtener el mayor rendimiento posible de este modelo, ajustaremos sus hiperparámetros mediante una búsqueda\n",
    "exhaustiva usando GridSearchCV.\n",
    "\n",
    "Los hiperparámetros comprobados con sus posibles valores son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty': ['None', 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3],\n",
    "    'shuffle': [False, True],\n",
    "    'eta0': [0.01, 0.1, 0.5, 1, 1.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A partir de este objeto de hiperparámetros, podemos obtener la mejor combinación de estos para nuestro clasificador\n",
    "mediante la clase de `scikit` GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = SGDClassifier(loss=\"perceptron\", max_iter=10000, random_state=5)\n",
    "grid_search = GridSearchCV(clf, param_grid=params, scoring='f1_micro')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best params: {}\".format(grid_search.best_params_))\n",
    "print(\"Best f1 score: %.5f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Los resultados de este modelo son los siguientes:\n",
    "\n",
    "| Clasificador       | F1 Score (test split)  | F1 Score (test data)  |\n",
    "| ------------------ |:----------------------:|:---------------------:|\n",
    "| Perceptrón         | 0.8778                 | 0.7158                |\n",
    "\n",
    "Entrenando el modelo con el total del conjunto de entrenamiento, obtenemos un F1-score en Kaggle de 0.7204."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "title": "Práctica 1: Clasificación de células"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}